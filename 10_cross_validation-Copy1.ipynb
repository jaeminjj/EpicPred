{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1642ad25-488f-4565-833e-368951b7b4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85a7186-dfb2-4a5f-b9fc-791605eec283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a08ffe-cb29-4365-b9c4-ffef08516d19",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COV-CCO-0162.csv',\n",
       " 'COV-CCO-0473.csv',\n",
       " 'COV-CCO-0131.csv',\n",
       " 'COV-CNC-0321.csv',\n",
       " 'COV-CCO-0281.csv',\n",
       " 'COV-CCO-0141.csv',\n",
       " 'COV-CCO-0211.csv',\n",
       " 'COV-CCO-0471.csv',\n",
       " 'COV-CCO-0384.csv',\n",
       " 'COV-CNC-0011.csv',\n",
       " 'COV-CCO-0272.csv',\n",
       " 'COV-CCO-0061.csv',\n",
       " 'COV-CCO-0091.csv',\n",
       " 'COV-CCO-0222.csv',\n",
       " 'COV-CCO-3631.csv',\n",
       " 'COV-CCO-0301.csv',\n",
       " 'COV-CCO-0303.csv',\n",
       " 'COV-CNC-0221.csv',\n",
       " 'COV-CCO-0322.csv',\n",
       " 'COV-CNC-0101.csv',\n",
       " 'COV-CCO-0152.csv',\n",
       " 'COV-CCO-0212.csv',\n",
       " 'COV-CCO-0931.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'COV-CCO-3371.csv',\n",
       " 'COV-CCO-0941.csv',\n",
       " 'COV-CCO-0355.csv',\n",
       " 'COV-CCO-0151.csv',\n",
       " 'COV-CCO-3691.csv',\n",
       " 'COV-CCO-0231.csv',\n",
       " 'COV-CCO-0253.csv',\n",
       " 'COV-CCO-0042.csv',\n",
       " 'COV-CCO-0354.csv',\n",
       " 'COV-CNC-0251.csv',\n",
       " 'COV-CCO-0383.csv',\n",
       " 'COV-CCO-0271.csv',\n",
       " 'COV-CCO-0201.csv',\n",
       " 'COV-CCO-0381.csv',\n",
       " 'COV-CCO-3583.csv',\n",
       " 'COV-CCO-0182.csv',\n",
       " 'COV-CCO-0012.csv',\n",
       " 'COV-CCO-0441.csv',\n",
       " 'COV-CCO-0321.csv',\n",
       " 'COV-CCO-0292.csv',\n",
       " 'COV-CCO-0323.csv',\n",
       " 'COV-CNC-0141.csv',\n",
       " 'COV-CNC-0051.csv',\n",
       " 'COV-CCO-0111.csv',\n",
       " 'COV-CCO-0921.csv',\n",
       " 'COV-CCO-0351.csv',\n",
       " 'COV-CNC-0461.csv',\n",
       " 'COV-CCO-0251.csv',\n",
       " 'COV-CCO-0391.csv',\n",
       " 'COV-CCO-0081.csv',\n",
       " 'COV-CCO-3614.csv',\n",
       " 'COV-CCO-0161.csv',\n",
       " 'COV-CNC-0301.csv',\n",
       " 'COV-CCO-2962.csv',\n",
       " 'COV-CNC-0391.csv',\n",
       " 'COV-CCO-0132.csv',\n",
       " 'COV-CNC-0131.csv',\n",
       " 'COV-CCO-0472.csv',\n",
       " 'COV-CCO-0302.csv',\n",
       " 'COV-CCO-0371.csv',\n",
       " 'COV-CCO-0282.csv',\n",
       " 'COV-CCO-0112.csv',\n",
       " 'COV-CCO-0102.csv',\n",
       " 'COV-CCO-0072.csv',\n",
       " 'COV-CCO-0171.csv',\n",
       " 'COV-CCO-0401.csv',\n",
       " 'COV-CCO-0352.csv',\n",
       " 'COV-CCO-0291.csv',\n",
       " 'COV-CNC-0231.csv',\n",
       " 'COV-CCO-0101.csv',\n",
       " 'COV-CCO-0173.csv',\n",
       " 'COV-CCO-3282.csv',\n",
       " 'COV-CCO-0442.csv',\n",
       " 'COV-CCO-0262.csv',\n",
       " 'COV-CCO-0172.csv',\n",
       " 'COV-CCO-0451.csv',\n",
       " 'COV-CCO-0192.csv',\n",
       " 'COV-CCO-0011.csv',\n",
       " 'COV-CCO-3461.csv',\n",
       " 'COV-CCO-0121.csv',\n",
       " 'COV-CCO-0361.csv',\n",
       " 'COV-CCO-0221.csv',\n",
       " 'COV-CCO-0311.csv',\n",
       " 'COV-CCO-0312.csv',\n",
       " 'COV-CCO-0232.csv',\n",
       " 'COV-CCO-0382.csv',\n",
       " 'COV-CCO-0353.csv',\n",
       " 'COV-CCO-0363.csv',\n",
       " 'COV-CCO-0071.csv',\n",
       " 'COV-CCO-0103.csv',\n",
       " 'COV-CCO-0911.csv',\n",
       " 'COV-CCO-0043.csv',\n",
       " 'COV-CCO-0951.csv',\n",
       " 'COV-CCO-0092.csv',\n",
       " 'COV-CCO-0261.csv',\n",
       " 'COV-CCO-0313.csv',\n",
       " 'COV-CCO-0041.csv',\n",
       " 'COV-CCO-0191.csv',\n",
       " 'COV-CCO-0082.csv',\n",
       " 'COV-CCO-0202.csv',\n",
       " 'COV-CCO-3372.csv',\n",
       " 'COV-CCO-0181.csv',\n",
       " 'COV-CCO-3122.csv',\n",
       " 'COV-CCO-0062.csv',\n",
       " 'COV-CCO-0142.csv',\n",
       " 'COV-CCO-0252.csv',\n",
       " 'COV-CNC-0401.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/tcr-bert/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca66936-c267-439f-bd5b-46b7d9c0466a",
   "metadata": {},
   "source": [
    "# data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4e6a6cf-c742-4f3a-9ac7-68c0f6fcb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real.csv')\n",
    "original_info=original_info.dropna(subset=['ICU_label'])\n",
    "R_list=list()\n",
    "p_list=list()\n",
    "for i in original_info.index:\n",
    "    if original_info.loc[i,'scTCR']==1 and original_info.loc[i,'BULK_TCR']==1:\n",
    "        p_list.append(original_info.loc[i,'sample'])\n",
    "        R_list.append(original_info.loc[i,'R_sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "196236fa-13f3-4eb2-ae43-8bb82d330a9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10413\n",
      "18271\n",
      "4169\n",
      "7217\n",
      "29361\n",
      "13180\n",
      "17049\n",
      "13521\n",
      "31066\n",
      "27296\n",
      "1152\n",
      "8582\n",
      "5699\n",
      "14502\n",
      "3263\n",
      "23861\n",
      "25824\n",
      "65017\n",
      "13488\n",
      "41442\n",
      "28760\n",
      "3100\n",
      "22494\n",
      "100000\n",
      "33686\n",
      "25787\n",
      "18966\n",
      "17809\n",
      "2326\n",
      "49224\n",
      "10146\n",
      "23763\n",
      "2365\n",
      "54039\n",
      "8323\n",
      "11052\n",
      "34520\n",
      "14512\n",
      "37450\n",
      "8516\n",
      "45262\n",
      "10616\n",
      "18147\n",
      "26484\n",
      "20101\n",
      "4845\n",
      "6164\n",
      "27235\n",
      "16549\n",
      "2524\n",
      "54322\n",
      "19910\n",
      "30456\n",
      "19846\n",
      "26113\n",
      "34838\n",
      "57653\n",
      "7377\n",
      "6768\n",
      "15477\n",
      "9158\n",
      "39041\n",
      "20583\n",
      "7878\n",
      "7289\n",
      "9915\n",
      "17161\n",
      "23207\n",
      "18195\n",
      "23432\n",
      "7870\n",
      "12305\n",
      "33273\n",
      "14542\n",
      "33333\n",
      "4252\n",
      "14814\n",
      "8998\n",
      "11557\n",
      "7672\n",
      "21295\n",
      "32971\n",
      "3377\n",
      "22167\n",
      "17204\n",
      "28221\n",
      "17861\n",
      "38134\n",
      "26052\n",
      "1947\n",
      "5570\n",
      "41093\n",
      "40093\n",
      "30146\n",
      "11009\n",
      "31350\n",
      "3815\n",
      "9902\n",
      "7939\n",
      "9301\n",
      "5759\n",
      "36867\n",
      "64073\n",
      "13395\n",
      "7527\n",
      "13334\n",
      "18276\n",
      "26683\n",
      "27648\n",
      "9303\n",
      "18381\n",
      "39009\n",
      "37060\n",
      "25183\n",
      "15866\n",
      "18008\n",
      "21023\n",
      "13026\n",
      "22328\n",
      "3691\n",
      "3257\n",
      "15820\n",
      "20632\n",
      "32966\n",
      "32333\n",
      "36249\n",
      "15938\n",
      "14468\n",
      "8062\n",
      "7753\n",
      "4448\n",
      "14291\n",
      "1074\n",
      "8632\n",
      "13092\n",
      "42200\n",
      "29414\n",
      "23217\n",
      "3307\n",
      "22201\n",
      "10570\n",
      "18450\n",
      "29786\n",
      "10962\n",
      "33057\n",
      "32826\n",
      "23936\n",
      "18985\n",
      "19229\n",
      "19703\n",
      "12503\n",
      "22403\n",
      "23005\n",
      "31570\n",
      "11858\n",
      "27873\n",
      "14768\n",
      "22258\n",
      "25056\n",
      "25793\n",
      "37796\n",
      "15647\n",
      "18392\n",
      "6815\n",
      "23879\n",
      "33010\n",
      "11302\n",
      "19932\n",
      "9611\n",
      "16847\n",
      "8540\n",
      "51574\n",
      "8648\n",
      "25247\n",
      "12655\n",
      "10353\n",
      "29251\n",
      "23874\n",
      "7653\n",
      "14653\n",
      "4139\n",
      "36249\n",
      "24837\n",
      "20464\n",
      "17237\n",
      "1770\n",
      "24634\n",
      "42641\n",
      "3173\n",
      "11488\n",
      "15358\n",
      "64246\n",
      "12726\n",
      "14417\n",
      "38136\n",
      "37066\n",
      "33735\n",
      "17095\n",
      "7753\n",
      "23770\n",
      "4059\n",
      "6401\n",
      "19304\n",
      "6701\n",
      "33658\n",
      "22936\n",
      "9534\n",
      "22998\n",
      "10032\n",
      "3959\n",
      "10313\n",
      "6392\n",
      "8165\n",
      "3650\n",
      "5016\n",
      "5912\n",
      "5658\n",
      "28859\n",
      "32903\n",
      "20040\n",
      "8903\n",
      "24244\n",
      "7178\n",
      "32924\n",
      "18182\n",
      "19640\n",
      "3494\n",
      "11179\n",
      "35756\n",
      "29035\n",
      "32927\n",
      "15062\n",
      "14451\n",
      "3119\n",
      "13987\n",
      "12622\n",
      "31097\n",
      "77210\n",
      "22262\n",
      "3751\n",
      "44244\n",
      "17261\n",
      "16689\n",
      "23702\n",
      "16695\n",
      "43075\n",
      "12534\n",
      "3913\n",
      "10562\n",
      "10654\n",
      "26185\n",
      "3756\n",
      "24709\n",
      "59008\n",
      "29793\n",
      "52865\n",
      "24734\n",
      "11234\n",
      "59073\n",
      "19132\n",
      "43037\n",
      "4208\n",
      "22510\n",
      "2423\n",
      "28468\n",
      "44875\n",
      "15918\n",
      "13850\n",
      "9750\n",
      "19579\n",
      "5557\n",
      "5152\n",
      "19322\n",
      "31572\n",
      "14138\n",
      "46477\n",
      "22326\n",
      "18623\n",
      "22002\n",
      "9039\n",
      "19873\n",
      "18203\n",
      "19094\n",
      "20655\n",
      "32008\n",
      "17226\n",
      "40977\n",
      "15652\n",
      "12056\n",
      "13628\n",
      "34500\n",
      "18722\n",
      "33564\n",
      "9607\n",
      "11739\n",
      "26002\n",
      "12751\n",
      "27041\n",
      "42774\n",
      "22929\n",
      "7743\n",
      "10212\n",
      "20082\n",
      "27768\n",
      "17114\n",
      "26596\n",
      "1397\n",
      "12379\n",
      "26418\n",
      "12749\n",
      "20434\n",
      "52083\n",
      "18747\n",
      "20597\n",
      "21971\n",
      "17467\n",
      "31895\n",
      "12655\n",
      "14678\n",
      "7591\n",
      "15937\n",
      "37984\n",
      "14776\n",
      "9229\n",
      "43579\n",
      "31318\n",
      "31425\n",
      "19149\n",
      "2186\n",
      "46740\n",
      "4858\n",
      "42340\n",
      "30160\n",
      "14529\n",
      "9777\n",
      "5750\n",
      "25101\n",
      "27560\n",
      "5220\n",
      "16560\n",
      "9331\n",
      "28016\n",
      "3289\n",
      "32671\n",
      "21450\n",
      "33410\n",
      "58850\n",
      "40815\n",
      "21440\n",
      "16469\n",
      "9183\n",
      "31663\n",
      "26468\n",
      "12972\n",
      "39363\n",
      "901\n",
      "79464\n",
      "25650\n",
      "32223\n",
      "17702\n",
      "36463\n",
      "18378\n",
      "14708\n",
      "715\n",
      "16209\n",
      "10449\n",
      "12905\n",
      "13780\n",
      "23728\n",
      "40041\n",
      "7898\n",
      "35175\n",
      "5582\n",
      "9123\n",
      "1924\n",
      "20758\n",
      "27155\n",
      "28539\n",
      "28421\n",
      "3967\n",
      "26298\n",
      "12234\n",
      "19352\n",
      "16976\n",
      "11539\n",
      "23192\n",
      "39381\n",
      "8573\n",
      "7205\n",
      "21480\n",
      "13344\n",
      "15457\n",
      "10639\n",
      "8795\n",
      "1627\n",
      "17793\n",
      "83205\n",
      "23178\n",
      "14572\n",
      "100000\n",
      "30949\n",
      "3984\n",
      "12969\n",
      "7452\n",
      "22772\n",
      "473\n",
      "18051\n",
      "14051\n",
      "65535\n",
      "43490\n",
      "14751\n",
      "6180\n",
      "25531\n",
      "43811\n",
      "12708\n",
      "9939\n",
      "19631\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/first/bulkTCR/TRB/'):\n",
    "    if i=='.ipynb_checkpoints':\n",
    "        continue\n",
    "    if i.split('.csv')[0] in p_list:\n",
    "        continue\n",
    "    file=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/first/bulkTCR/TRB/'+i)\n",
    "    \n",
    "    file=file[file['Read Count']>1]\n",
    "    file=file[['Read Count','CDR3 Amino Acid Sequence']]\n",
    "    file.columns=['barcode','cdr3']\n",
    "    if len(file.index)>=100000:\n",
    "        file=file.iloc[:100000,:]\n",
    "    print(len(file.index))\n",
    "    file[['barcode','cdr3']].to_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+i,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdb0132e-5c44-4bc0-a38a-edbb35745297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COV-CNO-0331.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.replace('.','-')[:-4]+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9adfffea-9dbd-4eee-974d-6779902c987f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/first/scTCR/filtered_beta/'):\n",
    "    if i=='.ipynb_checkpoints':\n",
    "        continue\n",
    "    \n",
    "    file=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/first/scTCR/filtered_beta/'+i)\n",
    "    if len(file.index)<=1000:\n",
    "        continue\n",
    "    file=file.sort_values('reads',ascending=False)\n",
    "    if len(file.index)>=100000:\n",
    "        file=file.iloc[:100000,:]\n",
    "    i=i.replace('.','-')[:-4]+'.csv'\n",
    "    file[['barcode','cdr3']].to_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+i,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9589be0-e528-4af9-9e2d-c06e8475dae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/second/bulkTCR/TRB/'):\n",
    "    if i=='.ipynb_checkpoints':\n",
    "        continue\n",
    "    if i.split('.csv')[0] in p_list:\n",
    "        continue\n",
    "    file=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/second/bulkTCR/TRB/'+i)\n",
    "    \n",
    "    file=file[file['Read Count']>1]\n",
    "    file=file[['Read Count','CDR3 Amino Acid Sequence']]\n",
    "    file.columns=['barcode','cdr3']\n",
    "    if len(file.index)>= 100000:\n",
    "        file=file.iloc[:100000,:]\n",
    "    #print(len(file.index))\n",
    "    file[['barcode','cdr3']].to_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+i,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb310d80-cdd6-4f97-b759-d96da70513fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/second/scTCR/filtered_beta/'):\n",
    "    if i=='.ipynb_checkpoints':\n",
    "        continue\n",
    "    \n",
    "    file=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/pre_processed/second/scTCR/filtered_beta/'+i)\n",
    "    #if len(file.index)>=200:\n",
    "    #    continue\n",
    "    file=file.sort_values('reads',ascending=False)\n",
    "    #if len(file.index)>=2000:\n",
    "    #    file=file.iloc[:2000,:]\n",
    "    file[['barcode','cdr3']].to_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+i,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e928841e-af50-40a7-adfd-7471986e4af6",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c1819a62-1efb-4bbd-9d5a-6bdc59a28897",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=list()\n",
    "for i in os.listdir('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR'):\n",
    "    list1.append(i.split('.csv')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8536ee4-b482-4446-aad9-f6b202cd9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=list()\n",
    "for i in os.listdir('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/Finetune/'):\n",
    "    if 'npy' in i:\n",
    "        list1.append(i.split('.npy')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6b590bdc-e98a-4d18-9e9f-84ec7623360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/length.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "48d0e335-ef89-4457-8898-5a9f01c46336",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=list(samples[samples.iloc[:,2]>1000]['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2cbcae5d-dcae-410e-9a45-2c126e8759e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=list(samples[samples.iloc[:,2]>5000]['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef32ad70-a896-4ffc-873f-565ed47a8cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real_v2.csv')\n",
    "sample_info.index=sample_info.iloc[:,0]\n",
    "sample_info=sample_info.dropna(subset=['WHO_label'])\n",
    "sample_info=sample_info[sample_info['sample'].isin(list1)]\n",
    "sample_info=sample_info[sample_info['BULK_TCR']==1]\n",
    "#sample_info=sample_info[sample_info['sample'].isin(list2)]\n",
    "sample_info=sample_info.drop_duplicates('patient')\n",
    "sample_info=sample_info[(sample_info['BULK_TCR'] == 1) | (sample_info['scTCR'] == 1)]\n",
    "original_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real_v2.csv')\n",
    "original_info=original_info.dropna(subset=['WHO_label'])\n",
    "original_info=original_info[original_info['sample'].isin(list1)]\n",
    "original_info=original_info[original_info['BULK_TCR']==1]\n",
    "#original_info=original_info[original_info['sample'].isin(list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880e5d0-b531-44ec-9cde-ff4d41d6dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd984eb-9e5b-4b16-ab51-46dacd8c27fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_samples[0]+valid_samples[0]+train_samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd585a83-3d28-499f-bf5f-f15b7dbb0879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "67\n",
      "262\n",
      "67\n",
      "260\n",
      "69\n",
      "263\n",
      "66\n",
      "269\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(sample_info['patient'], sample_info['WHO_label'], test_size=0.2, random_state=1)\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "k=5\n",
    "train_samples=[]\n",
    "valid_samples=[]\n",
    "test_samples=[]\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_kfold.split(list(X_train), list(sample_info.loc[X_train,'WHO_label']))):\n",
    "    \n",
    "    M=sample_info.loc[X_train,:]\n",
    "    train_patients=M.iloc[train_idx,0]\n",
    "    valid_patients=M.iloc[test_idx,0]\n",
    "    train_samples.append(list(original_info[original_info['patient'].isin(train_patients)]['sample']))\n",
    "    print(len(list(original_info[original_info['patient'].isin(train_patients)]['sample'])))\n",
    "    valid_samples.append(list(original_info[original_info['patient'].isin(valid_patients)]['sample']))\n",
    "    print(len(list(original_info[original_info['patient'].isin(valid_patients)]['sample'])))\n",
    "    test_samples.append(list(original_info[original_info['patient'].isin(X_temp)]['sample']))\n",
    "    #print(len(set(test_samples[0]+valid_samples[0]+train_samples[0])))\n",
    "    #if 'COV-CCO-0962' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-CCO-0962')\n",
    "    #if 'COV-CCO-0962' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-CCO-0962')\n",
    "    #if 'COV-CCO-0962' in valid_samples[fold]:\n",
    "        #valid_samples[fold].remove('COV-CCO-0962')\n",
    "    #if 'COV-CCO-1491' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-CCO-1491')\n",
    "    #if 'COV-CCO-1491' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-CCO-1491')\n",
    "    #if 'COV-CCO-1491' in valid_samples[fold]:\n",
    "    #    valid_samples[fold].remove('COV-CCO-1491')\n",
    "    #if 'COV-CCO-1792' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-CCO-1792')\n",
    "    #if 'COV-CCO-1792' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-CCO-1792')\n",
    "    #if 'COV-CCO-1792' in valid_samples[fold]:\n",
    "    #    valid_samples[fold].remove('COV-CCO-1792')\n",
    "    #if 'COV-MCO-0011' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-MCO-0011')\n",
    "    #if 'COV-MCO-0011' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-MCO-0011')\n",
    "    #if 'COV-MCO-0011' in valid_samples[fold]:\n",
    "    #    valid_samples[fold].remove('COV-MCO-0011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc3a9cd-9100-4e6e-83ca-5a890cf9fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train.pkl', 'wb') as file:\n",
    "    pickle.dump(train_samples, file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test.pkl', 'wb') as file:\n",
    "    pickle.dump(test_samples, file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/valid.pkl', 'wb') as file:\n",
    "    pickle.dump(valid_samples, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ad03f8-15a2-4b13-bae4-f64d0b11c928",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train_v3.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mtrain_samples\u001b[49m, file)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test_v3.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(test_samples, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_samples' is not defined"
     ]
    }
   ],
   "source": [
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train_v3.pkl', 'wb') as file:\n",
    "    pickle.dump(train_samples, file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test_v3.pkl', 'wb') as file:\n",
    "    pickle.dump(test_samples, file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/valid_v3.pkl', 'wb') as file:\n",
    "    pickle.dump(valid_samples, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "6bf37a5e-6f06-419e-95cf-90fc2c6076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_infor.csv')\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train.pkl', 'rb') as file:\n",
    "    train_samples = pickle.load(file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test.pkl', 'rb') as file:\n",
    "    test_samples = pickle.load(file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/valid.pkl', 'rb') as file:\n",
    "    valid_samples = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a299e3f9-031b-417d-a18d-08b570309ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7a42c-feab-49b0-b215-a7dcb779b29e",
   "metadata": {},
   "source": [
    "# SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e0789856-29c1-43cd-9626-002162a13598",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list=[]\n",
    "for i in os.listdir('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/sc_TCR_encoded'):\n",
    "    if 'npy' in i:\n",
    "        sample_list.append(i.split('.npy')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b18c1632-6091-4906-a35b-d6719f3a9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "f597dd8e-17e7-46f0-a2e4-144cd103e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real_v2.csv')\n",
    "sample_info.index=sample_info.iloc[:,0]\n",
    "sample_info=sample_info.dropna(subset=['WHO_label'])\n",
    "sample_info=sample_info[sample_info['sample'].isin(list2)]\n",
    "sample_info=sample_info.drop_duplicates('patient')\n",
    "sample_info=sample_info[(sample_info['BULK_TCR'] == 1) | (sample_info['scTCR'] == 1)]\n",
    "original_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real_v2.csv')\n",
    "original_info=original_info.dropna(subset=['WHO_label'])\n",
    "original_info=original_info[original_info['sample'].isin(list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "92c09e57-1eff-44b4-9128-9f0dbc5ecd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n",
      "84\n",
      "352\n",
      "98\n",
      "355\n",
      "95\n",
      "357\n",
      "93\n",
      "370\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(sample_info['patient'], sample_info['WHO_label'], test_size=0.2, random_state=1)\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "k=5\n",
    "train_samples=[]\n",
    "valid_samples=[]\n",
    "test_samples=[]\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(stratified_kfold.split(list(X_train), list(sample_info.loc[X_train,'WHO_label']))):\n",
    "    \n",
    "    M=sample_info.loc[X_train,:]\n",
    "    train_patients=M.iloc[train_idx,0]\n",
    "    valid_patients=M.iloc[test_idx,0]\n",
    "    train_samples.append(list(original_info[original_info['patient'].isin(train_patients)]['sample']))\n",
    "    print(len(list(original_info[original_info['patient'].isin(train_patients)]['sample'])))\n",
    "    valid_samples.append(list(original_info[original_info['patient'].isin(valid_patients)]['sample']))\n",
    "    print(len(list(original_info[original_info['patient'].isin(valid_patients)]['sample'])))\n",
    "    test_samples.append(list(original_info[original_info['patient'].isin(X_temp)]['sample']))\n",
    "    #print(len(set(test_samples[0]+valid_samples[0]+train_samples[0])))\n",
    "    #if 'COV-CCO-0962' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-CCO-0962')\n",
    "    #if 'COV-CCO-0962' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-CCO-0962')\n",
    "    #if 'COV-CCO-0962' in valid_samples[fold]:\n",
    "        #valid_samples[fold].remove('COV-CCO-0962')\n",
    "    #if 'COV-CCO-1491' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-CCO-1491')\n",
    "    #if 'COV-CCO-1491' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-CCO-1491')\n",
    "    #if 'COV-CCO-1491' in valid_samples[fold]:\n",
    "    #    valid_samples[fold].remove('COV-CCO-1491')\n",
    "    #if 'COV-CCO-1792' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-CCO-1792')\n",
    "    #if 'COV-CCO-1792' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-CCO-1792')\n",
    "    #if 'COV-CCO-1792' in valid_samples[fold]:\n",
    "    #    valid_samples[fold].remove('COV-CCO-1792')\n",
    "    #if 'COV-MCO-0011' in train_samples[fold]:\n",
    "    #    train_samples[fold].remove('COV-MCO-0011')\n",
    "    #if 'COV-MCO-0011' in test_samples[fold]:\n",
    "    #    test_samples[fold].remove('COV-MCO-0011')\n",
    "    #if 'COV-MCO-0011' in valid_samples[fold]:\n",
    "    #    valid_samples[fold].remove('COV-MCO-0011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "24a0f508-813c-40e5-8d2f-e091fd8bd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train_sc.pkl', 'wb') as file:\n",
    "    pickle.dump(train_samples, file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test_sc.pkl', 'wb') as file:\n",
    "    pickle.dump(test_samples, file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/valid_sc.pkl', 'wb') as file:\n",
    "    pickle.dump(valid_samples, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "76569638-666f-489b-8724-c12f4597dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1fa21d54-7e08-430b-b159-d9242e33fc85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['COV-CCO-0072', 'COV-CCO-0082', 'COV-CCO-0152', 'COV-CCO-0352', 'COV-CCO-0353', 'COV-CCO-0354', 'COV-CCO-0355', 'COV-CCO-0382', 'COV-CCO-0383', 'COV-CCO-0384', 'COV-CCO-0492', 'COV-CCO-0493', 'COV-CCO-1483', 'COV-CCO-1912', 'COV-CCO-1913', 'COV-CCO-1914', 'COV-CCO-1915', 'COV-SCO-0062', 'COV-SCO-0423', 'COV-CCO-3581', 'COV-CCO-3462', 'COV-CCO-3621', 'COV-CCO-3582', 'COV-CCO-2492', 'COV-CCO-2391', 'COV-CCO-3123', 'COV-MCO-0102', 'COV-CCO-3012', 'COV-CCO-2493', 'COV-CCO-2394', 'COV-CCO-2393', 'COV-CCO-3121', 'COV-CCO-3541'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [351]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_info\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m=\u001b[39msample_info\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m Counter(\u001b[43msample_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWHO_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1246\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:991\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m section\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot applicable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['COV-CCO-0072', 'COV-CCO-0082', 'COV-CCO-0152', 'COV-CCO-0352', 'COV-CCO-0353', 'COV-CCO-0354', 'COV-CCO-0355', 'COV-CCO-0382', 'COV-CCO-0383', 'COV-CCO-0384', 'COV-CCO-0492', 'COV-CCO-0493', 'COV-CCO-1483', 'COV-CCO-1912', 'COV-CCO-1913', 'COV-CCO-1914', 'COV-CCO-1915', 'COV-SCO-0062', 'COV-SCO-0423', 'COV-CCO-3581', 'COV-CCO-3462', 'COV-CCO-3621', 'COV-CCO-3582', 'COV-CCO-2492', 'COV-CCO-2391', 'COV-CCO-3123', 'COV-MCO-0102', 'COV-CCO-3012', 'COV-CCO-2493', 'COV-CCO-2394', 'COV-CCO-2393', 'COV-CCO-3121', 'COV-CCO-3541'] not in index\""
     ]
    }
   ],
   "source": [
    "sample_info.index=sample_info.iloc[:,1]\n",
    "Counter(sample_info.loc[valid_samples[4],'WHO_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0e05911e-2116-4a6b-9fec-e0c174edd7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length_list=[]\n",
    "length_open=[]\n",
    "sample=[]\n",
    "for i in list(set(test_samples[0]+valid_samples[0]+train_samples[0])):\n",
    "    t=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/Finetune/'+i+'_openmax_label.csv')\n",
    "    length_list.append(len(t[t.iloc[:,1]!='Z_unknown']))\n",
    "    length_open.append(len(t.index))\n",
    "    sample.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d5919d6e-8754-4265-b895-a6d3e3e1455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(pd.DataFrame([sample,length_list,length_open])).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/length.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf207067-7639-4ef0-8bfb-deb044c22f8c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14a662ae-9611-4416-8e3f-8e81a5f5755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real.csv')\n",
    "\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train.pkl', 'rb') as file:\n",
    "    train_samples = pickle.load(file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test.pkl', 'rb') as file:\n",
    "    test_samples = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3246391d-6d00-49a2-84c6-1f911c976beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9508bbb-57f0-4a51-8397-4ac9923e8dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81ceab00-515e-428c-9ebc-4b2828f7de00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236     COV-CCO-0802\n",
       "237     COV-CCO-0803\n",
       "256     COV-CCO-0871\n",
       "259     COV-CCO-0881\n",
       "260     COV-CCO-0891\n",
       "            ...     \n",
       "1271    COV-CNC-0491\n",
       "1272    COV-CCO-3281\n",
       "1273    COV-CCO-3221\n",
       "1274    COV-CCO-3541\n",
       "1276    COV-CCO-2651\n",
       "Name: sample, Length: 413, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info[sample_info['sample'].isin(train_samples[0])]['sample'][100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e3ccc2-a4d0-47ef-a56e-4cb8e7fad7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8a8e3e-a09e-4961-a95f-4b99f60696d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 05:42:53.809743: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 05:43:23.741578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43809 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\" # 0, 1, 2, 3 중 하나\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # GPU 점유 비율\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edabfccb-7890-496d-a48b-d5ebe0eb2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c407e7b-c69c-4cdb-8dc2-efe4384e8720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name_list=[\"BMILab/TCR-BERT-PositionLoss\",\"BMILab/TCR-BERT-MLM\",\"wukevin/tcr-bert\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728cfc7e-80aa-4100-83c7-c79f85fd8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=model_name_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563ee40a-c5cb-4412-953f-cd0dc9753187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=True)\n",
    "bert_model = AutoModel.from_pretrained(model_name).to(device) \n",
    "input_size = bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f478f4-cbe5-4b42-a4b9-bb48ea6ce247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       COV-CCO-0011\n",
       "1       COV-CCO-0012\n",
       "9       COV-CCO-0041\n",
       "10      COV-CCO-0042\n",
       "11      COV-CCO-0043\n",
       "            ...     \n",
       "1271    COV-CNC-0491\n",
       "1272    COV-CCO-3281\n",
       "1273    COV-CCO-3221\n",
       "1274    COV-CCO-3541\n",
       "1276    COV-CCO-2651\n",
       "Name: sample, Length: 513, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info[sample_info['sample'].isin(train_samples[0])]['sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732049c-0676-4a88-a05a-560d1183adb1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py:655: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=True)\n",
    "bert_model = AutoModel.from_pretrained(model_name).to(device) \n",
    "input_size = bert_model.config.hidden_size\n",
    "\n",
    "for sample in sample_info[sample_info['sample'].isin(train_samples[0])]['sample']:\n",
    "    sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+sample+'.csv')\n",
    "    if len(sample_raw['cdr3'].index)>=1000:\n",
    "        T=int(len(sample_raw['cdr3'].index)/1000)+1\n",
    "        T1=len(sample_raw['cdr3'].index)%1000\n",
    "        for i in range(0,T):\n",
    "            if i==T-1:\n",
    "                sequences = [' '.join(list(word)) for word in sample_raw['cdr3'][i*1000:]]\n",
    "            else:\n",
    "                sequences = [' '.join(list(word)) for word in sample_raw['cdr3'][i*1000:i*1000+1000]]\n",
    "            encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "            input_ids = encoded_inputs['input_ids'].to(device)\n",
    "            attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            if i==0:\n",
    "                df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "            else:\n",
    "                df1=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "                df=pd.concat([df,df1])\n",
    "    else:\n",
    "    \n",
    "    \n",
    "        sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "        encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "        input_ids = encoded_inputs['input_ids'].to(device)\n",
    "        attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "    k=30\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    pd.DataFrame(cluster_assignments).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/tcr-bert_cluster/'+sample+'.csv',index=False)\n",
    "    df.to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/tcr-bert/'+sample+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab56a10-dd9f-4118-b9e4-83dd59701fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in sample_info[sample_info['sample'].isin(test_samples[0])]['sample']:\n",
    "    sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+sample+'.csv')\n",
    "    if len(sample_raw['cdr3'].index)>=1000:\n",
    "        T=len(sample_raw['cdr3'].index)/1000\n",
    "        T1=len(sample_raw['cdr3'].index)%1000\n",
    "        for i in range(0,T):\n",
    "            if i==T-1:\n",
    "                sequences = [' '.join(list(word)) for word in sample_raw['cdr3'][n*1000:]]\n",
    "            else:\n",
    "                sequences = [' '.join(list(word)) for word in sample_raw['cdr3'][n*1000:n*1000+1000]]\n",
    "            encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "            input_ids = encoded_inputs['input_ids'].to(device)\n",
    "            attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "            outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "            df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "            df=pd.concat([df,df])\n",
    "    else:\n",
    "    \n",
    "    \n",
    "        sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "        encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "        input_ids = encoded_inputs['input_ids'].to(device)\n",
    "        attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "    k=30\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    pd.DataFrame(cluster_assignments).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/tcr-bert_cluster/'+sample+'.csv',index=False)\n",
    "    df.to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/tcr-bert/'+sample+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca0200-93cd-4583-87af-e4a8ffb2f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list=[\"BMILab/TCR-BERT-PositionLoss\",\"BMILab/TCR-BERT-MLM\",\"wukevin/tcr-bert\"]\n",
    "model_name=model_name_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58073775-5a67-4514-9eca-1733fba1a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in sample_info[sample_info['sample'].isin(train_samples[0])]['sample']:\n",
    "    sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+sample+'.csv')\n",
    "    sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "    encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = encoded_inputs['input_ids'].to(device)\n",
    "    attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "    k=30\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    pd.DataFrame(cluster_assignments).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert_cluster/'+sample+'.csv',index=False)\n",
    "    df.to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert/'+sample+'.csv',index=False)\n",
    "for sample in sample_info[sample_info['sample'].isin(test_samples[0])]['sample']:\n",
    "    sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+sample+'.csv')\n",
    "    sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "    encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = encoded_inputs['input_ids'].to(device)\n",
    "    attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "    k=30\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    pd.DataFrame(cluster_assignments).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert_cluster/'+sample+'.csv',index=False)\n",
    "    df.to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert/'+sample+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f87ed8-5a18-4df8-89de-5ed351c4b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list=[\"BMILab/TCR-BERT-PositionLoss\",\"BMILab/TCR-BERT-MLM\",\"wukevin/tcr-bert\"]\n",
    "model_name=model_name_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d3c56-f4e9-4899-89df-3d589771e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in sample_info[sample_info['sample'].isin(train_samples[0])]['sample']:\n",
    "    sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+sample+'.csv')\n",
    "    sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "    encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = encoded_inputs['input_ids'].to(device)\n",
    "    attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "    k=30\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    pd.DataFrame(cluster_assignments).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert-pos_cluster/'+sample+'.csv',index=False)\n",
    "    df.to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert-pos/'+sample+'.csv',index=False)\n",
    "for sample in sample_info[sample_info['sample'].isin(test_samples[0])]['sample']:\n",
    "    sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+sample+'.csv')\n",
    "    sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "    encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "    input_ids = encoded_inputs['input_ids'].to(device)\n",
    "    attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "    outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "    k=30\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(df)\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    pd.DataFrame(cluster_assignments).to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert-pos_cluster/'+sample+'.csv',index=False)\n",
    "    df.to_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_BERT/SNUH-bert-pos/'+sample+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b99701-d3cd-4fb5-bc63-8be4bca9a618",
   "metadata": {},
   "source": [
    "# SNUH 10 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59993810-e311-4ca8-a578-d25a71bd94dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepAttnMIL_Surv(nn.Module):\n",
    "    def __init__(self, cluster_num,class_num):\n",
    "        super(DeepAttnMIL_Surv, self).__init__()\n",
    "        \n",
    "        self.embedding_net = nn.Sequential(\n",
    "            nn.Linear(768, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(32, class_num),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.cluster_num = cluster_num\n",
    "    def masked_softmax(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Performs masked softmax, as simply masking post-softmax can be\n",
    "        inaccurate\n",
    "        :param x: [batch_size, num_items]\n",
    "        :param mask: [batch_size, num_items]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            mask = mask.float()\n",
    "        if mask is not None:\n",
    "            x_masked = x * mask + (1 - 1 / (mask+1e-5))\n",
    "        else:\n",
    "            x_masked = x\n",
    "        x_max = x_masked.max(1)[0]\n",
    "        x_exp = (x - x_max.unsqueeze(-1)).exp()\n",
    "        if mask is not None:\n",
    "            x_exp = x_exp * mask.float()\n",
    "        return x_exp / x_exp.sum(1).unsqueeze(-1)\n",
    "    def forward(self, x, label,method):\n",
    "        res = []\n",
    "        for i in range(self.cluster_num):\n",
    "            hh = torch.where(label == i)\n",
    "            #print(i)\n",
    "            # Embedding\n",
    "            output = self.embedding_net(x[hh].squeeze(1))\n",
    "            #print(i)\n",
    "            # Change the shape to (N, 1, 64) before Max Pooling\n",
    "            #output = output.squeeze(1)\n",
    "            output=output.reshape(64,-1)\n",
    "            #print(output.shape)\n",
    "            #max_pool = nn.MaxPool1d(kernel_size=output.shape[1])\n",
    "            if method =='mean':\n",
    "                average_pool = nn.AvgPool1d(kernel_size=output.shape[1])\n",
    "                \n",
    "            if method =='MAX':\n",
    "                average_pool = nn.MaxPool1d(kernel_size=output.shape[1])\n",
    "            if method =='AD':\n",
    "                average_pool = nn.AdaptiveAvgPool1d()\n",
    "            #output = max_pool(output)\n",
    "            output = average_pool(output)\n",
    "            #value_count[i]*output\n",
    "            #print(output.shape)\n",
    "            #output = output.view(output.size()[0], -1)\n",
    "            res.append(output)\n",
    "        h = torch.cat(res, dim=1)\n",
    "        #print(h.shape)\n",
    "        b = h.size(0)\n",
    "        c = h.size(1)\n",
    "\n",
    "        h = h.view(b, c)\n",
    "        h=h.reshape(-1,64)\n",
    "        A = self.attention(h)\n",
    "        #print(A.shape)\n",
    "        #print(h.shape)\n",
    "        A = torch.transpose(A, 1, 0)  # KxN\n",
    "\n",
    "        A = self.masked_softmax(A)\n",
    "        \n",
    "\n",
    "        M = torch.mm(A, h)  # KxL\n",
    "        #print(M)\n",
    "        Y_pred = self.fc6(M)\n",
    "        #print(Y_pred)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d440e05-b5b9-4eab-b3a1-725af3d3cedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bc6e4-e440-45de-bc3d-9031fc855b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=label_encoder.fit_transform(list(sample_info[sample_info['sample'].isin(train_samples[0])]['ICU_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3efa8d4b-d07e-48d6-964e-19d2246eeb34",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 47.54 GiB total capacity; 46.09 GiB already allocated; 40.00 MiB free; 46.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     12\u001b[0m k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:1015\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1015\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1023\u001b[0m     embedding_output,\n\u001b[1;32m   1024\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:235\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    232\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_ids)\n\u001b[1;32m    233\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m--> 235\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken_type_embeddings\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    237\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 47.54 GiB total capacity; 46.09 GiB already allocated; 40.00 MiB free; 46.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "#for epoch in range(1000):\n",
    "    for sample,label in zip(sample_info[sample_info['sample'].isin(train_samples[0])]['sample'],f):\n",
    "        print(num)\n",
    "        sample_raw=pd.read_csv('/workspace//jaeminjeon_950515/SNUH/TCR_v2/data/TCR/'+i)\n",
    "        sequences = [' '.join(list(word)) for word in sample_raw['cdr3']]\n",
    "        encoded_inputs = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "        input_ids = encoded_inputs['input_ids'].to(device)\n",
    "        attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "        outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())\n",
    "        k=30\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(df)\n",
    "        cluster_assignments = kmeans.labels_\n",
    "        label_tensor = torch.tensor(cluster_assignments).to(device)\n",
    "        data_tensor = outputs.last_hidden_state[:, 0, :]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_tensor, label_tensor,'mean')\n",
    "        if num==0:\n",
    "            output_all=output\n",
    "            label_all=torch.tensor(label).to(device)\n",
    "        else:\n",
    "            output_all=torch.cat([output_all,output])\n",
    "            output_all=torch.cat([ label_all,torch.tensor(label).to(device)])\n",
    "            num=1\n",
    "        \n",
    "        \n",
    "    #loss = criterion(output_all, torch.tensor([label_encoder.fit_transform(list(label_all))]).to(device).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c234f014-98c3-4424-9cc4-99c1bbcbf669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1709 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0     27\n",
       "1     13\n",
       "2     15\n",
       "3     16\n",
       "4     13\n",
       "...   ..\n",
       "1704  13\n",
       "1705  16\n",
       "1706   0\n",
       "1707   8\n",
       "1708   9\n",
       "\n",
       "[1709 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepAttnMIL_Surv(30, 3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.75,0.25]).to(device))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=True)\n",
    "bert_model = AutoModel.from_pretrained(model_name).to(device) \n",
    "input_size = bert_model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c53850c8-c9f5-414c-8579-646bf686b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 13, 15, ...,  0,  8,  9], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13108c41-24d2-4af0-aabb-eaf638d1b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(outputs.last_hidden_state[:, 0, :].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d3b8a856-79e3-4d26-82b8-942d8f980c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k=30\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(df)\n",
    "cluster_assignments = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8b39e2d4-863e-4987-b36b-8c153613e5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc012d9-02e4-4df6-ae67-4a96bf6e82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    train=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/Comparision/Train/'+data_name+'_'+chain+'.csv')\n",
    "                    #random.shuffle(train['Epitope'])\n",
    "                    test=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/Comparision/Test/'+data_name+'_'+chain+'.csv')\n",
    "                    train_sequences = [' '.join(list(word)) for word in train[chain]]\n",
    "                    test_sequences = [' '.join(list(word)) for word in test[chain]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3fb262-963a-4d19-a22c-fa07dc298375",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1355118443.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [7]\u001b[0;36m\u001b[0m\n\u001b[0;31m    huggingface-cli login\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "                                encoded_inputs = tokenizer(train_sequences, truncation=True, padding=True, return_tensors='pt')\n",
    "                                input_ids = encoded_inputs['input_ids'].to(device)\n",
    "                                attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "                                label_batch1 = torch.tensor(train_labels).to(device)\n",
    "                            \n",
    "                                # Iterate over batches\n",
    "                                for i in range(0, len(train_sequences), batch_size):\n",
    "                                    input_batch = input_ids[i:i+batch_size]\n",
    "                                    mask_batch = attention_mask[i:i+batch_size]\n",
    "                                    label_batch = label_batch1[i:i+batch_size]\n",
    "                            \n",
    "                                    # Forward pass\n",
    "                                    optimizer.zero_grad()\n",
    "                                    outputs = bert_model(input_batch, attention_mask=mask_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2813855-42db-4080-a569-05dd99314ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement huggingface-cli (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for huggingface-cli\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3201ce3-9b20-4e02-8542-7e0348eb5cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1355118443.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [9]\u001b[0;36m\u001b[0m\n\u001b[0;31m    huggingface-cli login\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f8e18-47cf-4704-81ea-81c93b2b5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeepAttnMIL_Surv(nn.Module):\n",
    "    def __init__(self, cluster_num,class_num):\n",
    "        super(DeepAttnMIL_Surv, self).__init__()\n",
    "        \n",
    "        self.embedding_net = nn.Sequential(\n",
    "            nn.Linear(768, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(32, class_num),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.cluster_num = cluster_num\n",
    "    def masked_softmax(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Performs masked softmax, as simply masking post-softmax can be\n",
    "        inaccurate\n",
    "        :param x: [batch_size, num_items]\n",
    "        :param mask: [batch_size, num_items]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            mask = mask.float()\n",
    "        if mask is not None:\n",
    "            x_masked = x * mask + (1 - 1 / (mask+1e-5))\n",
    "        else:\n",
    "            x_masked = x\n",
    "        x_max = x_masked.max(1)[0]\n",
    "        x_exp = (x - x_max.unsqueeze(-1)).exp()\n",
    "        if mask is not None:\n",
    "            x_exp = x_exp * mask.float()\n",
    "        return x_exp / x_exp.sum(1).unsqueeze(-1)\n",
    "    def forward(self, x, label,value_count,method):\n",
    "        res = []\n",
    "        for i in range(self.cluster_num):\n",
    "            hh = torch.where(label == i)\n",
    "            #print(i)\n",
    "            # Embedding\n",
    "            output = self.embedding_net(x[hh].squeeze(1))\n",
    "            #print(i)\n",
    "            # Change the shape to (N, 1, 64) before Max Pooling\n",
    "            #output = output.squeeze(1)\n",
    "            output=output.reshape(64,-1)\n",
    "            #print(output.shape)\n",
    "            #max_pool = nn.MaxPool1d(kernel_size=output.shape[1])\n",
    "            if method =='mean':\n",
    "                average_pool = nn.AvgPool1d(kernel_size=output.shape[1])\n",
    "                \n",
    "            if method =='MAX':\n",
    "                average_pool = nn.MaxPool1d(kernel_size=output.shape[1])\n",
    "            if method =='AD':\n",
    "                average_pool = nn.AdaptiveAvgPool1d()\n",
    "            #output = max_pool(output)\n",
    "            output = average_pool(output)\n",
    "            value_count[i]*output\n",
    "            #print(output.shape)\n",
    "            #output = output.view(output.size()[0], -1)\n",
    "            res.append(output)\n",
    "        h = torch.cat(res, dim=1)\n",
    "        #print(h.shape)\n",
    "        b = h.size(0)\n",
    "        c = h.size(1)\n",
    "\n",
    "        h = h.view(b, c)\n",
    "        h=h.reshape(-1,64)\n",
    "        A = self.attention(h)\n",
    "        #print(A.shape)\n",
    "        #print(h.shape)\n",
    "        A = torch.transpose(A, 1, 0)  # KxN\n",
    "\n",
    "        A = self.masked_softmax(A)\n",
    "        \n",
    "\n",
    "        M = torch.mm(A, h)  # KxL\n",
    "        #print(M)\n",
    "        Y_pred = self.fc6(M)\n",
    "        #print(Y_pred)\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "40cc2be9-7b92-4046-9844-c751997481c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info=pd.read_csv('/workspace/jaeminjeon_950515/SNUH/TCR_v2/metadata/sample_label_real_v2.csv')\n",
    "\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/train_v2.pkl', 'rb') as file:\n",
    "    train_samples = pickle.load(file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/test_v2.pkl', 'rb') as file:\n",
    "    test_samples = pickle.load(file)\n",
    "with open('/workspace/jaeminjeon_950515/SNUH/TCR_v2/data/TCR_meta/valid_v2.pkl', 'rb') as file:\n",
    "    valid_samples = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cb136926-6e8f-4fc5-9294-8e3f8e85e93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b452e7ee-cc0e-4e9b-ae43-ba5da3d7a3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'COV-CCO-3491' in test_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bd904-b1dc-41e1-8d84-a6acb8c7ee86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
